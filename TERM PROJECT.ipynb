{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project was to predict the survival of passengers supported a collection of information. we tend to used Kaggle competition \"Titanic: Machine Learning from Disaster\" (see https://www.kaggle.com/c/titanic/data) to retrieve necessary knowledge and measure accuracy of our predictions. The historical knowledge has been split into 2 teams, a 'training set' and a 'test set'. For the coaching set, we tend to square measure given the result (whether or not a traveller survived). we tend to used this set to make our model to get predictions for the check set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSYcS6rtlw3Z"
   },
   "source": [
    "## download the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "8G3zbIywlw3g"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.linear_model import LogisticRegression #Logistic regression\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
    "from sklearn.naive_bayes import GaussianNB # Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reFaYxP_lw3h"
   },
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "aWfzCzghlw3j"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdJ6hNABlw3j",
    "outputId": "92cccb38-0d09-4171-a049-4797059a8315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Test data come in CSV file and contain the following fields:    \n",
    "⦁\tPassenger ID \n",
    "⦁\tPassenger Class  \n",
    "⦁\tName  \n",
    "⦁\tSex  \n",
    "⦁\tAge  \n",
    "⦁\tNumber of passenger's siblings and spouses on board  \n",
    "⦁\tNumber of passenger's parents and children on board  \n",
    "⦁\tTicket  \n",
    "⦁\tFare  \n",
    "⦁\tCabin \n",
    "⦁\tCity where passenger embarked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWroV0xxlw3k"
   },
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYjaXU_Clw3l",
    "outputId": "e5aabf2b-8304-4c67-b551-290b981bd719"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
       "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.012658  \n",
       "Survived     0.257307  \n",
       "Pclass      -0.549500  \n",
       "Age          0.096067  \n",
       "SibSp        0.159651  \n",
       "Parch        0.216225  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "aDF0B94klw3l",
    "outputId": "8242a917-dbfd-4132-8163-4aee24fb9f1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation how many pasanger survived and how many dead \n",
    "\n",
    "def bar_chart(column):\n",
    "    survived=train[train[\"Survived\"]==1][column].value_counts()\n",
    "    dead=train[train[\"Survived\"]==0][column].value_counts()\n",
    "    df1=pd.DataFrame([survived,dead])\n",
    "    df1.index=[\"Survived\",\"Dead\"]\n",
    "    df1.plot(kind=\"bar\",figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart(\"Sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart(\"Pclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart(\"SibSp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart(\"Parch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart(\"Embarked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2BVXI3Qlw3m"
   },
   "source": [
    "## Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnQ8yV6hlw3n",
    "outputId": "a7e1bec0-6471-464c-a594-2edac52c6cc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "S38cH83clw3n"
   },
   "outputs": [],
   "source": [
    "train=train.drop(['Cabin'],axis=1)\n",
    "test=test.drop(['Cabin'],axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "aGqNnn5plw3n"
   },
   "outputs": [],
   "source": [
    "data=[train,test]\n",
    "for dataset in data:\n",
    "    dataset[\"Age\"]=dataset[\"Age\"].fillna(dataset[\"Age\"].mean(), inplace = False) \n",
    "    dataset[\"Embarked\"]=dataset[\"Embarked\"].fillna(\"S\", inplace = False)\n",
    "    dataset[\"Fare\"]=dataset[\"Fare\"].fillna(dataset[\"Fare\"].mean(), inplace = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCwB9XyQlw3o",
    "outputId": "2c525c0f-79df-4736-d074-0690771d2a53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9wmviTylw3q",
    "outputId": "8ce8f61a-1b88-44ca-ae8d-b1c754b3eec0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    537\n",
       "0    354\n",
       "Name: not_alone, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train, test]\n",
    "for dataset in data:\n",
    "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
    "    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n",
    "    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n",
    "    dataset['not_alone'] = dataset['not_alone'].astype(int)\n",
    "train['not_alone'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f0ZZo7Jlw3q"
   },
   "source": [
    "## Converting Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfdKIO57lw3q"
   },
   "source": [
    "#### Age&Frea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "ymtHt5QQlw3r"
   },
   "outputs": [],
   "source": [
    "data = [train, test]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset[\"Age\"]=dataset[\"Age\"].astype(\"int\")\n",
    "    dataset[\"Fare\"]=dataset[\"Fare\"].astype(\"int\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KHUsceWlw3r"
   },
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "Zs0IzMeBlw3s"
   },
   "outputs": [],
   "source": [
    "data = [train, test]\n",
    "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "\n",
    "for dataset in data:\n",
    "    # extract titles\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # replace titles with a more common title or as Rare\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr','Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    # convert titles into numbers\n",
    "    dataset['Title'] = dataset['Title'].map(titles)\n",
    "    # filling NaN with 0, to get safe\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "train= train.drop(['Name'], axis=1)\n",
    "test= test.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IU857OYglw3s"
   },
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "J0WN3jSmlw3t"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label=LabelEncoder()\n",
    "train[\"Sex\"]=label.fit_transform(train[\"Sex\"])\n",
    "test[\"Sex\"]=label.fit_transform(test[\"Sex\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd-TyOcRlw3t"
   },
   "source": [
    "#### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "OY44Q1KMlw3t"
   },
   "outputs": [],
   "source": [
    "data=[train,test]\n",
    "for dataset in data:\n",
    "    dataset= dataset.drop(['Ticket'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "amoxJshelw3t"
   },
   "outputs": [],
   "source": [
    "train= train.drop(['Ticket'], axis=1)\n",
    "test= test.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwGaoYCklw3t"
   },
   "source": [
    "#### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "YURxXxh9lw3u"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label=LabelEncoder()\n",
    "train[\"Embarked\"]=label.fit_transform(train[\"Embarked\"])\n",
    "test[\"Embarked\"]=label.fit_transform(test[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kWTriENlw3u",
    "outputId": "1a120f7f-ffde-43d2-9729-d7dea951eeb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    646\n",
       "0    168\n",
       "1     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXPHTgEtlw3u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l125s3uelw3u"
   },
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "GqdotHNFlw3v"
   },
   "outputs": [],
   "source": [
    "data = [train, test]\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3CpDsoYlw3v",
    "outputId": "be2e91e9-4bdd-41f9-e4d9-af14db639a69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    303\n",
       "6    148\n",
       "3    106\n",
       "5    103\n",
       "2     92\n",
       "1     71\n",
       "0     68\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "kjdatVd_lw3v"
   },
   "outputs": [],
   "source": [
    "train= train.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkPktWqdlw3v",
    "outputId": "47b5d1f3-395a-461b-8d1a-1c29c269f00b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>relatives</th>\n",
       "      <th>not_alone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  relatives  \\\n",
       "0         0       3    1    2      1      0     7         2          1   \n",
       "1         1       1    0    5      1      0    71         0          1   \n",
       "2         1       3    0    3      0      0     7         2          0   \n",
       "3         1       1    0    5      1      0    53         2          1   \n",
       "4         0       3    1    5      0      0     8         2          0   \n",
       "\n",
       "   not_alone  Title  \n",
       "0          0      1  \n",
       "1          0      3  \n",
       "2          1      2  \n",
       "3          0      3  \n",
       "4          1      1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDsnVeqnlw3w",
    "outputId": "efa32bee-6924-48c6-dc8d-40183c0b3c73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>relatives</th>\n",
       "      <th>not_alone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  relatives  \\\n",
       "0          892       3    1    5      0      0     7         1          0   \n",
       "1          893       3    0    6      1      0     7         2          1   \n",
       "2          894       2    1    6      0      0     9         1          0   \n",
       "3          895       3    1    3      0      0     8         2          0   \n",
       "4          896       3    0    2      1      1    12         2          2   \n",
       "\n",
       "   not_alone  Title  \n",
       "0          1      1  \n",
       "1          0      3  \n",
       "2          1      1  \n",
       "3          1      1  \n",
       "4          0      3  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXQ-G4pBlw3w"
   },
   "source": [
    "## Building Machine Learning Models with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "b9SlG7_plw3x"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(\"Survived\", axis=1)\n",
    "y_train = train[\"Survived\"]\n",
    "X_test  = test.drop(\"PassengerId\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiROxX9Flw3x",
    "outputId": "6127d170-163a-4a09-eb9b-4699596e887a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 10)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7awf25nlw3y"
   },
   "source": [
    "### 1:Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "bab-PK78lw3y"
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X973VJl8lw33"
   },
   "source": [
    "### 2:Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "WxadXYuJlw33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "Logistic_Regression = LogisticRegression() \n",
    "Logistic_Regression.fit(X_train, y_train)  \n",
    "Y_pred = Logistic_Regression.predict(X_test)  \n",
    "acc_Logistic_Regression = round(Logistic_Regression.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)  \n",
    "Y_pred = model.predict(X_test)  \n",
    "acc_NB = round(model.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVpUSERzlw34"
   },
   "source": [
    "### Which is the best Model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "u36Qg381lw34",
    "outputId": "f4e9313d-f29e-4ec9-f3ba-daebeffca38e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93.49</th>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81.93</th>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69.14</th>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model\n",
       "Score                    \n",
       "93.49       Random Forest\n",
       "81.93  LogisticRegression\n",
       "69.14                 SVM"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': ['Random Forest','LogisticRegression','SVM'],\n",
    "                        'Score': [ acc_random_forest,acc_LogisticRegression,acc_NB]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common issue with all machine learning algorithms is Overfitting. For Decision\n",
    "Tree, it means growing too large tree (with strong bias, small variation) so it loses\n",
    "its ability to generalize the data and to predict the output. In order to deal with\n",
    "overfitting, we can grow several decision trees(Random forest) and take the average of their\n",
    "predictions. \n",
    "\n",
    "In Random Forest, we grow N decision trees based on randomly selected subset of\n",
    "the data and randomly selected M fields, where 𝑀 = sqrt(𝑡𝑜𝑡𝑎𝑙  𝑜𝑓 𝑓𝑖𝑒𝑙𝑑)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 :logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.615, total=   0.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.624, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.618, total=   0.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.618, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.612, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.637, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.618, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.618, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.618, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.612, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.581, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.730, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.685, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.730, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.702, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.570, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.713, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.691, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.685, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.685, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.598, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.663, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.680, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.674, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.687, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.775, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.781, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.730, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.702, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.771, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.742, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.781, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.803, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.803, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.676, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.781, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.820, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.581, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.719, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.685, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.697, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.592, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.713, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.674, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.685, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.680, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.693, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.770, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.775, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.754, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.747, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.781, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.792, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.798, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.777, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.770, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.826, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.781, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.820, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.749, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.764, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.809, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.815, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.809, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.598, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.702, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.725, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.719, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.693, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.770, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.775, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.760, total=   0.1s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.764, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.820, total=   0.1s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.775, total=   0.1s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.787, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.788, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.747, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.820, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.792, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.843, total=   0.1s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.793, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.787, total=   0.1s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.809, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.804, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.792, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.781, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.831, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.693, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.770, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.775, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.708, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.765, total=   0.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.758, total=   0.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.803, total=   0.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.775, total=   0.2s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.781, total=   0.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.765, total=   0.2s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.742, total=   0.2s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.803, total=   0.3s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.770, total=   0.4s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.809, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.799, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.787, total=   0.1s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.809, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.792, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.837, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.827, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.809, total=   0.1s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.815, total=   0.1s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.787, total=   0.1s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.815, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1226698 , 0.23399083, 0.11263117, 0.03621444, 0.02253092,\n",
       "       0.2094285 , 0.04140223, 0.04254216, 0.01731484, 0.16127513])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.feature_importances_  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X_train)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 5)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_n = model.transform(X_test)\n",
    "X_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform all models with the most important "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion='entropy',max_depth= 8,max_features='auto',n_estimators=500)\n",
    "random_forest.fit(X_new, y_train)\n",
    "\n",
    "Y_prediction = random_forest.predict(X_n)\n",
    "\n",
    "random_forest.score(X_new, y_train)\n",
    "acc_random_forest = round(random_forest.score(X_new, y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.68"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogisticRegression = LogisticRegression(C=0.1, penalty='l2') \n",
    "LogisticRegression.fit(X_new, y_train)  \n",
    "Y_pred = LogisticRegression.predict(X_n)  \n",
    "acc_LogisticRegression = round(LogisticRegression.score(X_new, y_train) * 100, 2)\n",
    "acc_LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.24"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(C=1000,gamma=0.0001, kernel='rbf')\n",
    "model.fit(X_new, y_train)  \n",
    "Y_pred = model.predict(X_n)  \n",
    "acc_NB = round(model.score(X_new, y_train) * 100, 2)\n",
    "acc_NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above results, we can conclude that Random forest is the best model before and after applying feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SfdKIO57lw3q",
    "1KHUsceWlw3r",
    "IU857OYglw3s",
    "Rd-TyOcRlw3t",
    "qwGaoYCklw3t",
    "l125s3uelw3u"
   ],
   "name": "CODE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
